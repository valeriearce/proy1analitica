{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>9966.000000</td>\n",
       "      <td>9993.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.623396e+09</td>\n",
       "      <td>1.380544</td>\n",
       "      <td>1.744021</td>\n",
       "      <td>1486.277500</td>\n",
       "      <td>945.810500</td>\n",
       "      <td>37.695162</td>\n",
       "      <td>-94.652247</td>\n",
       "      <td>1.574891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.021025e+07</td>\n",
       "      <td>0.615410</td>\n",
       "      <td>0.942354</td>\n",
       "      <td>1076.507968</td>\n",
       "      <td>655.755736</td>\n",
       "      <td>5.495851</td>\n",
       "      <td>15.759805</td>\n",
       "      <td>3.762395e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.508654e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>21.315500</td>\n",
       "      <td>-158.022100</td>\n",
       "      <td>1.568744e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.509248e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>33.679850</td>\n",
       "      <td>-101.301700</td>\n",
       "      <td>1.568781e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.668610e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1270.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>38.809800</td>\n",
       "      <td>-93.651600</td>\n",
       "      <td>1.577358e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.668626e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>41.349800</td>\n",
       "      <td>-82.209975</td>\n",
       "      <td>1.577359e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.668663e+09</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>52500.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>61.594000</td>\n",
       "      <td>-70.191600</td>\n",
       "      <td>1.577362e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    bathrooms     bedrooms         price   square_feet  \\\n",
       "count  1.000000e+04  9966.000000  9993.000000  10000.000000  10000.000000   \n",
       "mean   5.623396e+09     1.380544     1.744021   1486.277500    945.810500   \n",
       "std    7.021025e+07     0.615410     0.942354   1076.507968    655.755736   \n",
       "min    5.508654e+09     1.000000     0.000000    200.000000    101.000000   \n",
       "25%    5.509248e+09     1.000000     1.000000    949.000000    649.000000   \n",
       "50%    5.668610e+09     1.000000     2.000000   1270.000000    802.000000   \n",
       "75%    5.668626e+09     2.000000     2.000000   1695.000000   1100.000000   \n",
       "max    5.668663e+09     8.500000     9.000000  52500.000000  40000.000000   \n",
       "\n",
       "          latitude    longitude          time  \n",
       "count  9990.000000  9990.000000  1.000000e+04  \n",
       "mean     37.695162   -94.652247  1.574891e+09  \n",
       "std       5.495851    15.759805  3.762395e+06  \n",
       "min      21.315500  -158.022100  1.568744e+09  \n",
       "25%      33.679850  -101.301700  1.568781e+09  \n",
       "50%      38.809800   -93.651600  1.577358e+09  \n",
       "75%      41.349800   -82.209975  1.577359e+09  \n",
       "max      61.594000   -70.191600  1.577362e+09  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('datos_apartamentos_rent.xlsx')\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El price_type puede ser Monthly o Weekly. Por esto algunos precios estan en temporalidad semanal\n",
    "#Se multiplica por 4 los precios cuyo price-type es weekly para que pueda ser tomado como mensual\n",
    "df1.loc[df1[\"price_type\"] == \"Weekly\", \"price\"] *= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se seleccionan solo las columnas price, square feet, time\n",
    "colfiltrar = [ \"square_feet\",\"price\", \"time\"]\n",
    "columnasfiltradas = df1[colfiltrar]\n",
    "\n",
    "#QI,cuartil3 y rango intercuartil\n",
    "cuartil1 = columnasfiltradas.quantile(0.25)\n",
    "cuartil3 = columnasfiltradas.quantile(0.75)\n",
    "IQR = cuartil3 - cuartil1\n",
    "\n",
    "\n",
    "#limites\n",
    "limsuperior = cuartil3 + 1.5 * IQR\n",
    "liminferior = cuartil1 - 1.5 * IQR\n",
    "\n",
    "# se seleccionan los valores segun los limites\n",
    "df = df1[~((columnasfiltradas < liminferior) | (columnasfiltradas > limsuperior)).any(axis=1)]\n",
    "\n",
    "#Guardar en un excel nuevo para revisar\n",
    "#df.to_excel(\"datossinoutliers.xlsx\", index=False, engine=\"openpyxl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8939, 22)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solo hay 10 datos null de latitude y longitude. \n",
    "# Por lo tanto se decide eliminar las 10 filas donde esta null en latitude/longitude\n",
    "\n",
    "#eliminar datos de filas null en latitude\n",
    "df = df.dropna(subset=[\"latitude\"])\n",
    "\n",
    "#eliminar datos de filas null en longitude\n",
    "df = df.dropna(subset=[\"longitude\"])\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arced\\AppData\\Local\\Temp\\ipykernel_9940\\527669980.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['cityname'].fillna('Lebanon', inplace=True)\n",
      "C:\\Users\\arced\\AppData\\Local\\Temp\\ipykernel_9940\\527669980.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['state'].fillna('KS', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#se detecto que los datos null de ciudad y estado pertenecen a las coordenadas 39.8163,-98.5576\n",
    "#por lo tanto se reemplaza por la ciudad y estado de esta coordenada \n",
    "#Se busco en google maps lo cual coincidio con Lebanon, Kansas\n",
    "\n",
    "# Reemplazar los valores NaN con el Lebanon en ciudad\n",
    "df['cityname'].fillna('Lebanon', inplace=True)\n",
    "\n",
    "# Reemplazar los valores NaN con el KS en el Estado\n",
    "df['state'].fillna('KS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arced\\AppData\\Local\\Temp\\ipykernel_9940\\3973032556.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['bathrooms'].fillna(promediobathrooms, inplace=True)\n",
      "C:\\Users\\arced\\AppData\\Local\\Temp\\ipykernel_9940\\3973032556.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['bedrooms'].fillna(promediobedrooms, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#en las variables numericas donde hay datos faltantes se cambia el dato faltante por el promedio\n",
    "\n",
    "#promedio bathrooms\n",
    "promediobathrooms = df['bathrooms'].mean()\n",
    "\n",
    "# Reemplazar los valores NaN con el promedio\n",
    "df['bathrooms'].fillna(promediobathrooms, inplace=True)\n",
    "\n",
    "\n",
    "#promedio bedrooms\n",
    "promediobedrooms = df['bedrooms'].mean()\n",
    "\n",
    "# Reemplazar los valores NaN con el promedio\n",
    "df['bedrooms'].fillna(promediobedrooms, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arced\\AppData\\Local\\Temp\\ipykernel_9940\\3769906864.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['pets_allowed'].fillna(modapets_allowed, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#en las variables no numericas donde hay datos faltantes se cambia el dato faltante por la moda\n",
    "\n",
    "#moda pets_allowed\n",
    "modapets_allowed = df['pets_allowed'].mode()[0]\n",
    "\n",
    "# Reemplazar los valores NaN con la moda\n",
    "df['pets_allowed'].fillna(modapets_allowed, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir las características y crear columnas binarias\n",
    "amenities_sep = df[\"amenities\"].str.get_dummies(sep=\",\")\n",
    "\n",
    "# Concatenar con el DataFrame original\n",
    "df2 = pd.concat([df, amenities_sep], axis=1)\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo\n",
    "#df2.to_excel(\"datosfinalesapartamentos.xlsx\", index=False, engine=\"openpyxl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estadisticas descriptivas datos faltantes gestionados y sin outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>time</th>\n",
       "      <th>AC</th>\n",
       "      <th>Alarm</th>\n",
       "      <th>...</th>\n",
       "      <th>Patio/Deck</th>\n",
       "      <th>Playground</th>\n",
       "      <th>Pool</th>\n",
       "      <th>Refrigerator</th>\n",
       "      <th>Storage</th>\n",
       "      <th>TV</th>\n",
       "      <th>Tennis</th>\n",
       "      <th>View</th>\n",
       "      <th>Washer Dryer</th>\n",
       "      <th>Wood Floors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.939000e+03</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8.939000e+03</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "      <td>8939.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.621104e+09</td>\n",
       "      <td>1.277722</td>\n",
       "      <td>1.596888</td>\n",
       "      <td>1283.489093</td>\n",
       "      <td>831.843830</td>\n",
       "      <td>37.745092</td>\n",
       "      <td>-93.972328</td>\n",
       "      <td>1.574770e+09</td>\n",
       "      <td>0.070030</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261774</td>\n",
       "      <td>0.086699</td>\n",
       "      <td>0.350599</td>\n",
       "      <td>0.319499</td>\n",
       "      <td>0.164895</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>0.113659</td>\n",
       "      <td>0.035686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.137500e+07</td>\n",
       "      <td>0.472152</td>\n",
       "      <td>0.773917</td>\n",
       "      <td>486.941657</td>\n",
       "      <td>303.541291</td>\n",
       "      <td>5.566135</td>\n",
       "      <td>15.168417</td>\n",
       "      <td>3.825170e+06</td>\n",
       "      <td>0.255212</td>\n",
       "      <td>0.047251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439625</td>\n",
       "      <td>0.281409</td>\n",
       "      <td>0.477184</td>\n",
       "      <td>0.466309</td>\n",
       "      <td>0.371107</td>\n",
       "      <td>0.147543</td>\n",
       "      <td>0.224098</td>\n",
       "      <td>0.122853</td>\n",
       "      <td>0.317415</td>\n",
       "      <td>0.185517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.508654e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>21.315500</td>\n",
       "      <td>-158.022100</td>\n",
       "      <td>1.568744e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.509230e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>33.529250</td>\n",
       "      <td>-98.525300</td>\n",
       "      <td>1.568780e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.668609e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>38.911800</td>\n",
       "      <td>-93.627600</td>\n",
       "      <td>1.577358e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.668625e+09</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>41.507300</td>\n",
       "      <td>-82.195450</td>\n",
       "      <td>1.577359e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.668643e+09</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2810.000000</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>61.594000</td>\n",
       "      <td>-70.191600</td>\n",
       "      <td>1.577362e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    bathrooms     bedrooms        price  square_feet  \\\n",
       "count  8.939000e+03  8939.000000  8939.000000  8939.000000  8939.000000   \n",
       "mean   5.621104e+09     1.277722     1.596888  1283.489093   831.843830   \n",
       "std    7.137500e+07     0.472152     0.773917   486.941657   303.541291   \n",
       "min    5.508654e+09     1.000000     0.000000   200.000000   101.000000   \n",
       "25%    5.509230e+09     1.000000     1.000000   915.000000   630.000000   \n",
       "50%    5.668609e+09     1.000000     1.000000  1200.000000   777.000000   \n",
       "75%    5.668625e+09     1.500000     2.000000  1554.000000  1000.000000   \n",
       "max    5.668643e+09     4.000000     6.000000  2810.000000  1776.000000   \n",
       "\n",
       "          latitude    longitude          time           AC        Alarm  ...  \\\n",
       "count  8939.000000  8939.000000  8.939000e+03  8939.000000  8939.000000  ...   \n",
       "mean     37.745092   -93.972328  1.574770e+09     0.070030     0.002237  ...   \n",
       "std       5.566135    15.168417  3.825170e+06     0.255212     0.047251  ...   \n",
       "min      21.315500  -158.022100  1.568744e+09     0.000000     0.000000  ...   \n",
       "25%      33.529250   -98.525300  1.568780e+09     0.000000     0.000000  ...   \n",
       "50%      38.911800   -93.627600  1.577358e+09     0.000000     0.000000  ...   \n",
       "75%      41.507300   -82.195450  1.577359e+09     0.000000     0.000000  ...   \n",
       "max      61.594000   -70.191600  1.577362e+09     1.000000     1.000000  ...   \n",
       "\n",
       "        Patio/Deck   Playground         Pool  Refrigerator      Storage  \\\n",
       "count  8939.000000  8939.000000  8939.000000   8939.000000  8939.000000   \n",
       "mean      0.261774     0.086699     0.350599      0.319499     0.164895   \n",
       "std       0.439625     0.281409     0.477184      0.466309     0.371107   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "75%       1.000000     0.000000     1.000000      1.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "                TV       Tennis         View  Washer Dryer  Wood Floors  \n",
       "count  8939.000000  8939.000000  8939.000000   8939.000000  8939.000000  \n",
       "mean      0.022262     0.053026     0.015326      0.113659     0.035686  \n",
       "std       0.147543     0.224098     0.122853      0.317415     0.185517  \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000      0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000      0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000      0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000      1.000000     1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicos has_photo= ['Thumbnail' 'Yes' 'No']\n",
      "contar has_photo= has_photo\n",
      "Thumbnail    7914\n",
      "Yes           859\n",
      "No            166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#valores unicos columna has_photo\n",
    "unicoshas_photo = df2['has_photo'].unique()\n",
    "print (\"unicos has_photo=\", unicoshas_photo)\n",
    "\n",
    "#veces que aparecen los únicos de columna has_photo\n",
    "df2.groupby(['has_photo']).count()\n",
    "\n",
    "contarhas_photo = df2['has_photo'].value_counts()\n",
    "print(\"contar has_photo=\", contarhas_photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicos cityname= ['Washington' 'Evansville' 'Arlington' ... 'American Canyon' 'Belgrade'\n",
      " 'Locust']\n",
      "contar cityname= cityname\n",
      "Austin         521\n",
      "Dallas         208\n",
      "Houston        181\n",
      "San Antonio    177\n",
      "Chicago        131\n",
      "Name: count, dtype: int64\n",
      "contar cityname todos= cityname\n",
      "Austin             521\n",
      "Dallas             208\n",
      "Houston            181\n",
      "San Antonio        177\n",
      "Chicago            131\n",
      "                  ... \n",
      "American Canyon      1\n",
      "Saint Johns          1\n",
      "Mustang              1\n",
      "Morrow               1\n",
      "Grandy               1\n",
      "Name: count, Length: 1441, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#valores unicos columna cityname\n",
    "unicoscityname = df2['cityname'].unique()\n",
    "print (\"unicos cityname=\", unicoscityname)\n",
    "\n",
    "#veces que aparecen los únicos de columna cityname\n",
    "df2.groupby(['cityname']).count()\n",
    "\n",
    "#se extrajeron las 5 ciudades que mas se repiten debido a la gran cantidad de estados\n",
    "contarcityname = df['cityname'].value_counts().head()\n",
    "print(\"contar cityname=\", contarcityname)\n",
    "\n",
    "#aca se muestran todos las ciudades en caso de que se necesite ver las veces que se repite cada uno\n",
    "contarcityname1 = df['cityname'].value_counts()\n",
    "print(\"contar cityname todos=\", contarcityname1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicos state= ['DC' 'IN' 'VA' 'WA' 'NY' 'CA' 'AZ' 'NC' 'TX' 'GA' 'FL' 'AL' 'MD' 'CO'\n",
      " 'NM' 'IL' 'TN' 'AK' 'MA' 'KS' 'NJ' 'OR' 'DE' 'PA' 'IA' 'SC' 'MN' 'MI'\n",
      " 'KY' 'WI' 'OH' 'CT' 'RI' 'NV' 'UT' 'MO' 'OK' 'NH' 'NE' 'LA' 'ND' 'AR'\n",
      " 'ID' 'HI' 'MT' 'VT' 'SD' 'WV' 'MS' 'ME' 'WY']\n",
      "contar state= state\n",
      "TX    1674\n",
      "CA     620\n",
      "WA     475\n",
      "MD     412\n",
      "NC     396\n",
      "Name: count, dtype: int64\n",
      "contar state todos= state\n",
      "TX    1674\n",
      "CA     620\n",
      "WA     475\n",
      "MD     412\n",
      "NC     396\n",
      "GA     336\n",
      "NJ     329\n",
      "OH     300\n",
      "CO     298\n",
      "WI     294\n",
      "FL     291\n",
      "IL     258\n",
      "MO     230\n",
      "IN     213\n",
      "MN     212\n",
      "VA     185\n",
      "PA     175\n",
      "IA     174\n",
      "OR     168\n",
      "OK     162\n",
      "MI     155\n",
      "KS     136\n",
      "MA     130\n",
      "AZ     115\n",
      "ND     107\n",
      "NV     105\n",
      "NE     101\n",
      "CT      97\n",
      "TN      84\n",
      "UT      71\n",
      "NH      69\n",
      "DC      66\n",
      "NY      62\n",
      "SD      61\n",
      "LA      60\n",
      "SC      55\n",
      "AR      51\n",
      "AL      45\n",
      "AK      43\n",
      "KY      39\n",
      "ID      18\n",
      "VT      15\n",
      "NM      14\n",
      "RI      10\n",
      "MS       9\n",
      "HI       6\n",
      "MT       5\n",
      "DE       3\n",
      "WV       2\n",
      "ME       2\n",
      "WY       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#valores unicos columna state\n",
    "unicosstate = df2['state'].unique()\n",
    "print (\"unicos state=\", unicosstate)\n",
    "\n",
    "#veces que aparecen los únicos de columna state\n",
    "df2.groupby(['state']).count()\n",
    "\n",
    "#se extrajeron los 5 estados que mas se repiten debido a la gran cantidad de estados\n",
    "contarstate = df2['state'].value_counts().head()\n",
    "print(\"contar state=\", contarstate)\n",
    "\n",
    "#aca se muestran todos los estados en caso de que se necesite ver las veces que se repite cada uno\n",
    "contarstate1 = df2['state'].value_counts()\n",
    "print(\"contar state todos=\", contarstate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicos pets_allowed= ['Cats,Dogs' 'Cats' 'Dogs']\n",
      "contar pets_allowed= pets_allowed\n",
      "Cats,Dogs    8415\n",
      "Cats          453\n",
      "Dogs           71\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#valores unicos columna pets_allowed\n",
    "unicospets_allowed = df2['pets_allowed'].unique()\n",
    "print (\"unicos pets_allowed=\", unicospets_allowed)\n",
    "\n",
    "#veces que aparecen los únicos de columna pets_allowed\n",
    "df2.groupby(['pets_allowed']).count()\n",
    "\n",
    "contarpets_allowed = df2['pets_allowed'].value_counts()\n",
    "print(\"contar pets_allowed=\", contarpets_allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicos source= ['RentLingo' 'Listanza' 'RentDigs.com' 'ListedBuy' 'GoSection8'\n",
      " 'RealRentals' 'RENTOCULAR' 'rentbits' 'Home Rentals' 'Real Estate Agent'\n",
      " 'RENTCafé' 'tenantcloud']\n",
      "contar source= source\n",
      "RentLingo            6031\n",
      "RentDigs.com         2606\n",
      "ListedBuy             169\n",
      "RealRentals            66\n",
      "GoSection8             30\n",
      "Listanza               18\n",
      "RENTOCULAR             13\n",
      "rentbits                2\n",
      "Home Rentals            1\n",
      "Real Estate Agent       1\n",
      "RENTCafé                1\n",
      "tenantcloud             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#valores unicos columna source\n",
    "unicossource = df2['source'].unique()\n",
    "print (\"unicos source=\", unicossource)\n",
    "\n",
    "#veces que aparecen los únicos de columna source\n",
    "df2.groupby(['source']).count()\n",
    "\n",
    "contarsource = df2['source'].value_counts()\n",
    "print(\"contar source=\", contarsource)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
